{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KetkiGupta99/Plant-Disease-Classification/blob/main/Final_Project_Plant_Disease_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eI49N8_6quQ0",
        "outputId": "35b62824-ce61-4862-b032-bc9cdfee7ddc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.11/dist-packages (1.5.1)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.9/433.9 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.17 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install torchsummary\n",
        "%pip install -qU langchain_community pymupdf langchain-google-genai langchain-core"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchsummary import summary\n",
        "from torchvision.transforms import Resize\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "Y6mRzS16q1ZJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ati_OT49rV68",
        "outputId": "26da470d-6fdd-41ac-f224-8788c1584eeb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "genai_model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n"
      ],
      "metadata": {
        "id": "1tJuGetsabxJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "\n",
        "# # Get the current working directory.\n",
        "# current_directory = os.getcwd()\n",
        "\n",
        "# # Get a list of all the files and folders in the current directory.\n",
        "# files_and_folders = os.listdir(current_directory)"
      ],
      "metadata": {
        "id": "SjMYGq1ircLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# files_and_folders"
      ],
      "metadata": {
        "id": "fhvekDCYtERR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#  os.path.isdir()\n",
        "os.removedirs(\"/content/test/.ipynb_checkpoints\")"
      ],
      "metadata": {
        "id": "6Bb7P3yNtG5u"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# # Replace this line:\n",
        "# # os.path.isdir()\n",
        "# # with the following to provide a path string:\n",
        "# path_to_check = \"/content/test\"  # Replace with your desired path\n",
        "# is_directory = os.path.isdir(path_to_check)\n",
        "# print(f\"Is '{path_to_check}' a directory? {is_directory}\")\n",
        "# os.removedirs(\"/content/test/.ipynb_checkpoints\")"
      ],
      "metadata": {
        "id": "wPQNMtO2R6OX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def predict_image(img, model):\n",
        "#     \"\"\"Converts image to array and return the predicted class\n",
        "#         with highest probability\"\"\"\n",
        "#     # Convert to a batch of 1\n",
        "#     xb = to_device(img.unsqueeze(0), device)\n",
        "#     # Get predictions from model\n",
        "#     yb = model(xb)\n",
        "#     # Pick index with highest probability\n",
        "#     _, preds  = torch.max(yb, dim=1)\n",
        "#     # Retrieve the class label\n",
        "\n",
        "#     return classes[preds[0].item()], _, preds, yb"
      ],
      "metadata": {
        "id": "7nKquAWz51er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#output1, output2, output3, output4 = predict_image(img, model)"
      ],
      "metadata": {
        "id": "SNr_O3MP6Z3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# m = nn.Softmax(dim=1)\n",
        "# output = m(output4)\n",
        "# output\n",
        "\n",
        "# 0.000000000014776"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEaVxMWp5iCB",
        "outputId": "3419f901-04a3-4323-e834-6441d3e25da3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.4776e-02, 1.5278e-01, 5.3535e-01, 1.9247e-04, 1.3535e-01, 5.1425e-02,\n",
              "         1.1752e-07, 1.1378e-02, 2.6986e-03, 1.2227e-06, 5.1673e-06, 4.1536e-07,\n",
              "         5.1227e-04, 2.3448e-09, 2.3360e-07, 1.6222e-07, 2.8472e-02, 7.2829e-03,\n",
              "         7.3155e-06, 2.5507e-06, 7.7857e-06, 2.2154e-07, 8.9569e-04, 2.3707e-07,\n",
              "         1.6729e-08, 1.1146e-06, 7.6545e-07, 1.6025e-06, 1.7239e-06, 1.8109e-02,\n",
              "         1.1349e-02, 2.4861e-02, 8.6174e-06, 4.1895e-07, 4.0758e-03, 4.6972e-09,\n",
              "         8.2566e-06, 4.4201e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1bM6nzfEzHS",
        "outputId": "26878089-665c-42ed-df9b-fbddbac26bb9",
        "collapsed": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.44.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.35.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.44.1-py3-none-any.whl (9.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.44.1 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "\n",
        "import os\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    streaming=True,\n",
        "    callbacks=[StreamingStdOutCallbackHandler()]\n",
        "    # other params...\n",
        ")"
      ],
      "metadata": {
        "id": "AWH7R2mxb4p3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a13c36b5-06ef-429e-f2e3-386624a7808b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Unexpected argument 'streaming' provided to ChatGoogleGenerativeAI. Did you mean: 'disable_streaming'?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # from torchvision.transforms import Resize\n",
        "# test_dir = \"../content/test\"\n",
        "# transform = transforms.Compose([\n",
        "#     Resize((256, 256)),\n",
        "#     transforms.ToTensor(),\n",
        "\n",
        "# ])\n",
        "# test = ImageFolder(test_dir, transform=transform)\n",
        "\n",
        "# img, label = test[0]"
      ],
      "metadata": {
        "id": "0NMRSG_9Y4u-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "\n",
        "import streamlit as st\n",
        "from torchvision.transforms import Resize\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchsummary import summary\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    Resize((256, 256)),  # Resize to 224x224\n",
        "    transforms.ToTensor(),  # Convert image to tensor\n",
        "      # Normalize\n",
        "])\n",
        "classes = ['Apple___Apple_scab',\n",
        " 'Apple___Black_rot',\n",
        " 'Apple___Cedar_apple_rust',\n",
        " 'Apple___healthy',\n",
        " 'Blueberry___healthy',\n",
        " 'Cherry_(including_sour)___Powdery_mildew',\n",
        " 'Cherry_(including_sour)___healthy',\n",
        " 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot',\n",
        " 'Corn_(maize)___Common_rust_',\n",
        " 'Corn_(maize)___Northern_Leaf_Blight',\n",
        " 'Corn_(maize)___healthy',\n",
        " 'Grape___Black_rot',\n",
        " 'Grape___Esca_(Black_Measles)',\n",
        " 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)',\n",
        " 'Grape___healthy',\n",
        " 'Orange___Haunglongbing_(Citrus_greening)',\n",
        " 'Peach___Bacterial_spot',\n",
        " 'Peach___healthy',\n",
        " 'Pepper,_bell___Bacterial_spot',\n",
        " 'Pepper,_bell___healthy',\n",
        " 'Potato___Early_blight',\n",
        " 'Potato___Late_blight',\n",
        " 'Potato___healthy',\n",
        " 'Raspberry___healthy',\n",
        " 'Soybean___healthy',\n",
        " 'Squash___Powdery_mildew',\n",
        " 'Strawberry___Leaf_scorch',\n",
        " 'Strawberry___healthy',\n",
        " 'Tomato___Bacterial_spot',\n",
        " 'Tomato___Early_blight',\n",
        " 'Tomato___Late_blight',\n",
        " 'Tomato___Leaf_Mold',\n",
        " 'Tomato___Septoria_leaf_spot',\n",
        " 'Tomato___Spider_mites Two-spotted_spider_mite',\n",
        " 'Tomato___Target_Spot',\n",
        " 'Tomato___Tomato_Yellow_Leaf_Curl_Virus',\n",
        " 'Tomato___Tomato_mosaic_virus',\n",
        " 'Tomato___healthy']\n",
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "class ImageClassificationBase(nn.Module):\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                   # Generate prediction\n",
        "        loss = F.cross_entropy(out, labels)  # Calculate loss\n",
        "        acc = accuracy(out, labels)          # Calculate accuracy\n",
        "        return {\"val_loss\": loss.detach(), \"val_accuracy\": acc}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x[\"val_loss\"] for x in outputs]\n",
        "        batch_accuracy = [x[\"val_accuracy\"] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()       # Combine loss\n",
        "        epoch_accuracy = torch.stack(batch_accuracy).mean()\n",
        "        return {\"val_loss\": epoch_loss, \"val_accuracy\": epoch_accuracy} # Combine accuracies\n",
        "\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_accuracy']))\n",
        "\n",
        "def ConvBlock(in_channels, out_channels, pool=False):\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "             nn.BatchNorm2d(out_channels),\n",
        "             nn.ReLU(inplace=True)]\n",
        "    if pool:\n",
        "        layers.append(nn.MaxPool2d(4))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "# resnet architecture\n",
        "class ResNet9(ImageClassificationBase):\n",
        "    def __init__(self, in_channels, num_diseases):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = ConvBlock(in_channels, 64)\n",
        "        self.conv2 = ConvBlock(64, 128, pool=True) # out_dim : 128 x 64 x 64\n",
        "        self.res1 = nn.Sequential(ConvBlock(128, 128), ConvBlock(128, 128))\n",
        "\n",
        "        self.conv3 = ConvBlock(128, 256, pool=True) # out_dim : 256 x 16 x 16\n",
        "        self.conv4 = ConvBlock(256, 512, pool=True) # out_dim : 512 x 4 x 44\n",
        "        self.res2 = nn.Sequential(ConvBlock(512, 512), ConvBlock(512, 512))\n",
        "\n",
        "        self.classifier = nn.Sequential(nn.MaxPool2d(4),\n",
        "                                       nn.Flatten(),\n",
        "                                       nn.Linear(512, num_diseases))\n",
        "\n",
        "    def forward(self, xb): # xb is the loaded batch\n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "        out = self.res1(out) + out\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.res2(out) + out\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available:\n",
        "        return torch.device(\"cuda\")\n",
        "    else:\n",
        "        return torch.device(\"cpu\")\n",
        "device = get_default_device()\n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "def predict_image(img, model):\n",
        "    \"\"\"Converts image to array and return the predicted class\n",
        "        with highest probability\"\"\"\n",
        "    # Convert to a batch of 1\n",
        "    xb = to_device(img.unsqueeze(0), device)\n",
        "    # Get predictions from model\n",
        "    yb = model(xb)\n",
        "    # Pick index with highest probability\n",
        "    _, preds  = torch.max(yb, dim=1)\n",
        "    probs = F.softmax(yb, dim=1)  # Get probabilities\n",
        "\n",
        "    # Retrieve the class label\n",
        "\n",
        "    return classes[preds[0].item()], probs[0][preds[0]].item() * 100\n",
        "\n",
        "\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "placeholder = st.empty()\n",
        "if uploaded_file is not None:\n",
        "  placeholder.empty()\n",
        "  save_image_path = '/content/test/test/'+uploaded_file.name\n",
        "  with open(save_image_path, \"wb\") as f:\n",
        "      f.write(uploaded_file.getbuffer())\n",
        "  image = Image.open(save_image_path)\n",
        "\n",
        "  template = \"\"\"You are a Image Analyzer. You need to look at image and describe the image.\n",
        "\n",
        "Note: If image content doesn't contain information releated to leaves like \"Apple,Blueberry,Cherry,Corn,Grape,Orange,Peach,Pepper,Potato,Raspberry,Soybean,Squash,Strawberry,Tomato\" then reply \"Kindly upload valid leaf image\".\n",
        "\"\"\"\n",
        "\n",
        "  # Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
        "  GOOGLE_API_KEY= \"AIzaSyDxM8ikpclQUPuaZ2fZGETn81IKjQPo8E8\"\n",
        "  genai.configure(api_key=GOOGLE_API_KEY)\n",
        "  genai_model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "  response = genai_model.generate_content([template,image])\n",
        "  text=response.candidates[0].content.parts[0].text\n",
        "\n",
        "  # if text == \"Kindly upload valid leaf image.\":\n",
        "  #   placeholder.empty()\n",
        "  #   placeholder.write(text)\n",
        "\n",
        "\n",
        "  test_dir = \"../content/test\"\n",
        "  test = ImageFolder(test_dir, transform=transform)\n",
        "\n",
        "  img, label = test[0]\n",
        "  device = get_default_device()\n",
        "  model = to_device(ResNet9(3, len(classes)), device)\n",
        "  model.load_state_dict(torch.load('/content/drive/MyDrive/Model/plant-disease-model.pth', weights_only=True))\n",
        "  model.eval()\n",
        "  prediction, probability = predict_image(img.cuda(), model)\n",
        "\n",
        "  with placeholder.container():\n",
        "    st.image(save_image_path)\n",
        "    st.write(\"Prediction: \", prediction)\n",
        "    st.write(f\"Confidence: {probability:.2f}%\")\n",
        "    st.write(text)\n",
        "  if \"Kindly upload valid leaf image\".lower().strip() in text.lower().strip():\n",
        "    st.write(\"\")\n",
        "    placeholder.empty()\n",
        "    st.write(text)\n",
        "  for filename in os.listdir(\"/content/test/test\"):\n",
        "    if not filename.endswith(\".ipynb_checkpoints\"):\n",
        "      os.remove(os.path.join(\"/content/test/test\", filename))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OJmMVDsqFxf",
        "outputId": "558383a6-8dac-4448-95ee-239bc79c3ab3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # print(filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvguherOdQl3",
        "outputId": "86595987-8268-4523-a0a7-7cb6a9a3a3b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apple.jpeg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qp9jp2qVHFiz",
        "outputId": "6b56e08e-1cbd-4b63-bac7-31cf6c315de2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K\n",
            "added 22 packages in 4s\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/content/logs.txt & npx lt --port 8501 --subdomain plantdiseaseclassification & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBnTMIKvHGVc",
        "outputId": "f752c69f-eeda-4acc-f834-a7e1e4d6e80f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.240.196.95\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0Kyour url is: https://plantdiseaseclassification.loca.lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip"
      ],
      "metadata": {
        "id": "GA6YMkzRIJqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pkill -f localtunnel\n",
        "# !pkill -f lt"
      ],
      "metadata": {
        "id": "MSFsY2TnQ-Lh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}